{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\nimport os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n\nimport tensorflow as tf\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport openslide\nfrom openslide import OpenSlide\nimport tensorflow as tf\nfrom tensorflow.keras import Model\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n\nfrom sklearn.model_selection import train_test_split\n\nfrom tqdm import tqdm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/mayo-clinic-strip-ai/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/mayo-clinic-strip-ai/test.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"train_df[\"file_path\"] = train_df[\"image_id\"].apply(lambda x: \"../input/mayo-clinic-strip-ai/train/\" + x + \".tif\")\ntest_df[\"file_path\"]  = test_df[\"image_id\"].apply(lambda x: \"../input/mayo-clinic-strip-ai/test/\" + x + \".tif\")\ntrain_df[\"Y\"] = train_df[\"label\"].apply(lambda x : 1 if x==\"CE\" else 0) # Creating truth labels","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ndef preprocess(image_path):\n    slide = OpenSlide(image_path)\n    region = (1000,1000)    \n    size = (5000, 5000)\n    image = slide.read_region(region, 0, size)\n    image = tf.image.resize(image, (1024, 1024))\n    image = np.array(image)    \n    return image\n\n\ntrain_x=[]\nfor i in tqdm(train_df['file_path']):\n    x1=preprocess(i)\n    train_x.append(x1)\n\n\ntrain_x = np.array(train_x)/255.0\ntrain_y = train_df[\"Y\"]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nmodel = Sequential()\ninput_shape = (512, 512, 4)\n\n\n\nmodel.add(Conv2D(filters=32, kernel_size = (3,3), strides = 2, padding = 'same', activation = 'relu', input_shape = input_shape))\nmodel.add(Conv2D(filters=64, kernel_size = (3,3), strides = 2, padding = 'same', activation = 'relu'))\n\nmodel.add(layers.BatchNormalization())\nmodel.add(Dropout(0.20))\n\nmodel.add(Conv2D(filters=64, kernel_size = (3,3), strides = 2, padding = 'same', activation = 'relu'))\nmodel.add(Conv2D(filters=64, kernel_size = (3,3), strides = 2, padding = 'same', activation = 'relu'))\n\nmodel.add(layers.BatchNormalization())\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = 'relu'))\nmodel.add(Dropout(0.20))\nmodel.add(Dense(1))\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"%%time\ntrain_y = train_df[\"Y\"]\ntrain_x,test_x,train_y,test_y=train_test_split(train_x,train_y,test_size=0.2)\n\nimport math\nfrom tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping, Callback, ReduceLROnPlateau \n\n\n\n\nmodel.compile(\n    loss = tf.keras.losses.MeanSquaredError(),    \n    metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"rmse\"), \n             tf.keras.metrics.BinaryAccuracy(name=\"accuracy\")],\n    optimizer = tf.keras.optimizers.Adam(3e-4))\n\nhistory = model.fit(\n    train_x,\n    train_y,\n    epochs = 50,\n    batch_size=32,\n    validation_data = (test_x,test_y),\n    shuffle=True,\n    verbose = 1,\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Epochs: {len(history.history['accuracy'])}\")\nprint(f\"Accuracy: {history.history['accuracy'][-1]}\")\nprint(f\"Validation Accuracy: {history.history['val_accuracy'][-1]}\")\nprint(f\"Loss: {history.history['loss'][-1]}\")\nprint(f\"Validation Loss: {history.history['val_loss'][-1]}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"%%time\ntest_s=[]\nfor i in test_df['file_path']:\n    x1=preprocess(i)\n    test_s.append(x1)\ntest_s=np.array(test_s)/255.0\n\nsub_pred=model.predict(test_s)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame(test_df[\"patient_id\"].copy())\nsubmission[\"CE\"] = sub_pred\nsubmission[\"CE\"] = submission[\"CE\"].apply(lambda x : 0 if x<0 else x)\nsubmission[\"CE\"] = submission[\"CE\"].apply(lambda x : 1 if x>1 else x)\nsubmission[\"LAA\"] = 1- submission[\"CE\"]\n\nsubmission = submission.groupby(\"patient_id\").mean()\nsubmission = submission[[\"CE\", \"LAA\"]].round(6).reset_index()\nsubmission","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv(\"submission.csv\", index = False)\n!head submission.csv","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}